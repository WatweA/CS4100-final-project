{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list([\n",
    "    \"SPY\",  # S&P 500 Index Fund\n",
    "    \"IWV\",  # Russell 3000 Index Fund\n",
    "    \"QQQ\",  # Technology Sector Fund\n",
    "    \"IYF\",  # Financials Sector Fund\n",
    "    \"XLP\",  # Consumer Staples Sector Fund\n",
    "    \"XLU\",  # Utilities Sector Funds\n",
    "    \"XLV\",  # Health Care Sector Funds\n",
    "    \"IGE\",  # NA Natural Resources ETF\n",
    "    \"XLE\"  # Energy Sector Fund\n",
    "])\n",
    "\n",
    "indicators = {\n",
    "    \"3M_TBILL\": \"DTB3\",  # 3-Month Treasury Bill: Secondary Market Rate\n",
    "    \"CPI\": \"MEDCPIM158SFRBCLE\",  # Median Consumer Price Index\n",
    "    \"VIX\": \"VIXCLS\",  # CBOE Volatility Index\n",
    "    \"INDP\": \"INDPRO\",  # Industrial Production: Total Index\n",
    "    \"USHY_ADJ\": \"BAMLH0A0HYM2\",  # ICE BofA US High Yield Index Option-Adjusted Spread\n",
    "    \"US_LEADING\": \"USSLIND\",  # Leading Index for the United States\n",
    "    \"30Y_FRMTG\": \"MORTGAGE30US\",  # 30-Year Fixed Rate Mortgage Average in the United States\n",
    "    \"15Y_FRMTG\": \"MORTGAGE15US\",  # 15-Year Fixed Rate Mortgage Average in the United States\n",
    "    \"CPI_URBAN\": \"CUSR0000SEHA\",  # Consumer Price Index for All Urban Consumers: Rent of Primary Residence in U.S. City Average\n",
    "    \"RETAIL\": \"RSAFS\",  # Advance Retail Sales: Retail and Food Services, Total\n",
    "    \"PHARMA\": \"PCU32543254\",  # Producer Price Index by Industry: Pharmaceutical and Medicine Manufacturing\n",
    "    \"UNEMP\": \"UNRATE\",  # Unemployment Rate\n",
    "    \"UNEMP_PERM\": \"LNS13026638\",  # Unemployment Level - Permanent Job Losers\n",
    "    \"UNEMP_MEN\": \"LNS14000001\",  # Unemployment Rate - Men\n",
    "    \"UNEMP_WMN\": \"LNS14000002\",  # Unemployment Rate - Women\n",
    "    \"UNEMP_WHT\": \"LNS14000003\",  # Unemployment Rate - White\n",
    "    \"UNEMP_BLK\": \"LNS14000006\",  # Unemployment Rate - Black or African American\n",
    "    \"UNEMP_HIS\": \"LNS14000009\",  # Unemployment Rate - Hispanic or Latino\n",
    "    \"INC\": \"PI\",  # Personal Income\n",
    "    \"INC_DISP\": \"DSPIC96\",  # Real Disposable Personal Income\n",
    "    \"INC_DISP_PC\": \"A229RX0\",  # Real Disposable Personal Income: Per Capita\n",
    "    \"TAX_HIGH\": \"IITTRHB\",  # U.S Individual Income Tax: Tax Rates for Regular Tax: Highest Bracket\n",
    "    \"TAX_LOW\": \"IITTRLB\"  # U.S Individual Income Tax: Tax Rates for Regular Tax: Lowest Bracket\n",
    "}\n",
    "\n",
    "features = []\n",
    "for ticker in tickers:\n",
    "    features.append(f'{ticker}_1D_RET')\n",
    "    features.append(f'{ticker}_1D_VOL')\n",
    "    for timeframe in ['1W', '1M', '3M', '6M', '1Y']:\n",
    "        for calculation in ['RET', 'STD', 'VOL']:\n",
    "            features.append(f'{ticker}_{timeframe}_{calculation}')\n",
    "for indicator in indicators.keys():\n",
    "    features.append(indicator)\n",
    "\n",
    "\"\"\"\n",
    "We will use all 25 target columns in the neural network, for now we will use only the SPY 1 month return\n",
    "targets = [f'{ticker}_TARGET' for ticker in tickers] +\\\n",
    "    ['3M_TBILL', 'CPI', 'VIX', 'INDP', 'USHY_ADJ', '30Y_FRMTG', '15Y_FRMTG', 'RETAIL', 'PHARMA', 'UNEMP', 'INC']\n",
    "\"\"\"\n",
    "targets = ['SPY_TARGET']\n",
    "\n",
    "\n",
    "# construct a dictionary with all market data in divided into sets and features/targets\n",
    "dates = mcal.get_calendar('NYSE').schedule(start_date='2004-01-01', end_date='2020-12-31').index\n",
    "market_data = dict({\n",
    "    \"X\" : pd.read_pickle(\"data/market_data.zip\").loc[:, features],\n",
    "    \"y\" : pd.read_pickle(\"data/market_data.zip\").loc[:, targets]\n",
    "})\n",
    "market_data[\"X_train\"] = market_data[\"X\"].loc['2004-01-01':'2015-12-31', :]\n",
    "market_data[\"y_train\"] = market_data[\"y\"].loc['2004-01-01':'2015-12-31', :]\n",
    "market_data[\"X_test\"] = market_data[\"X\"].loc['2016-01-01':'2020-12-31', :]\n",
    "market_data[\"y_test\"] = market_data[\"y\"].loc['2016-01-01':'2020-12-31', :]\n",
    "market_data[\"X\"] = market_data[\"X\"].loc['2004-01-01':'2020-12-31', :]\n",
    "market_data[\"y\"] = market_data[\"y\"].loc['2004-01-01':'2020-12-31', :]\n",
    "\n",
    "# Create split on train_all with -1 for training data and 0 for validation data (data after '2013-01-01')\n",
    "split = PredefinedSplit(test_fold=[0 if v else -1 for v in market_data[\"X_train\"].index < '2013-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform and Scale the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(4383, 176)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_data[\"X_train\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# add in quantiles as additional feature columns\n",
    "quantile_transformer = QuantileTransformer()\n",
    "quantile_transformer.fit(market_data[\"X_train\"])\n",
    "market_data[\"X_train\"].loc[:, [col + \"_QUANTILE\" for col in features]] = pd.DataFrame(\n",
    "    quantile_transformer.transform(market_data[\"X_train\"]), index=market_data[\"X_train\"].index,\n",
    "    columns=[col + \"_QUANTILE\" for col in features])\n",
    "market_data[\"X_test\"].loc[:, [col + \"_QUANTILE\" for col in features]] = pd.DataFrame(\n",
    "    quantile_transformer.transform(market_data[\"X_test\"]), index=market_data[\"X_test\"].index,\n",
    "    columns=[col + \"_QUANTILE\" for col in features])\n",
    "\n",
    "# scale all data based on the training set\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler(with_mean=False)\n",
    "X_scaler.fit(market_data[\"X_train\"])\n",
    "y_scaler.fit(market_data[\"y_train\"])\n",
    "\n",
    "X_train = pd.DataFrame(X_scaler.transform(market_data[\"X_train\"]),\n",
    "                       index=market_data[\"X_train\"].index, columns=market_data[\"X_train\"].columns)\n",
    "y_train = pd.DataFrame(y_scaler.transform(market_data[\"y_train\"]),\n",
    "                       index=market_data[\"y_train\"].index, columns=market_data[\"y_train\"].columns)\n",
    "X_test = pd.DataFrame(X_scaler.transform(market_data[\"X_test\"]),\n",
    "                      index=market_data[\"X_test\"].index, columns=market_data[\"X_test\"].columns)\n",
    "y_test = pd.DataFrame(y_scaler.transform(market_data[\"y_test\"]),\n",
    "                      index=market_data[\"y_test\"].index, columns=market_data[\"y_test\"].columns)\n",
    "assert not any([any(arr) for arr in np.array(np.isinf(X_train))])\n",
    "assert not any([any(arr) for arr in np.array(np.isnan(X_train))])\n",
    "assert not any([any(arr) for arr in np.array(np.isinf(X_test))])\n",
    "assert not any([any(arr) for arr in np.array(np.isnan(X_test))])\n",
    "assert not any([any(arr) for arr in np.array(np.isinf(y_train))])\n",
    "assert not any([any(arr) for arr in np.array(np.isnan(y_train))])\n",
    "assert not any([any(arr) for arr in np.array(np.isinf(y_test))])\n",
    "assert not any([any(arr) for arr in np.array(np.isnan(y_test))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def to_signal(x):\n",
    "    return np.array([1 if 0 <= yt else -1 for yt in np.array(x).ravel()])\n",
    "\n",
    "def classification_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    A method to evaluate the true return values versus the predicted value as a binary classification task, where\n",
    "    values greater than 0 are set to 1, values under 0 are set to -1\n",
    "\n",
    "    :param y_true: true 1-month look-ahead return values\n",
    "    :param y_pred: predicted 1-month look-ahead return values\n",
    "    \"\"\"\n",
    "    true_classes = to_signal(y_true)#.reshape(-1, 1)\n",
    "    pred_classes = to_signal(y_pred)#.reshape(-1, 1)\n",
    "\n",
    "    accuracy = accuracy_score(true_classes, pred_classes)\n",
    "    cnf_mat = confusion_matrix(true_classes, pred_classes, labels=[1, -1])\n",
    "    print(f\"Confusion Matrix\\n{cnf_mat}\")\n",
    "    print(f\"Accuracy            = {accuracy:.04f}\\n\"\n",
    "          f\"F1-Score (Micro)    = {f1_score(true_classes, pred_classes, average='micro'):.04f}\\n\"\n",
    "          f\"F1-Score (Macro)    = {f1_score(true_classes, pred_classes, average='macro'):.04f}\\n\"\n",
    "          f\"F1-Score (Weighted) = {f1_score(true_classes, pred_classes, average='weighted'):.04f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': GridSearchCV(estimator=ElasticNet(max_iter=100000, tol=0.004), param_grid={\n",
    "        'l1_ratio': [0.4, 0.5, 0.6]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "    'Support Vector Machine': GridSearchCV(estimator=SVR(), param_grid={\n",
    "        'kernel': [\"linear\", \"rbf\", \"poly\"],\n",
    "        'degree': [2, 3, 4]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "    'Random Forest': GridSearchCV(estimator=RandomForestRegressor(bootstrap=True, n_jobs=-1), param_grid={\n",
    "        \"n_estimators\": [n for n in range(50, 175, 25)],\n",
    "        \"ccp_alpha\": [0.01, 0.05, 0.10]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "    'Adaptive Boost': GridSearchCV(estimator=AdaBoostRegressor(), param_grid={\n",
    "        \"n_estimators\": [n for n in range(50, 250, 50)],\n",
    "        \"loss\": [\"linear\", \"exponential\"],\n",
    "        \"learning_rate\": [0.01, 0.1, 1]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "    'Gradient Boost': GridSearchCV(estimator=GradientBoostingRegressor(loss=\"huber\"), param_grid={\n",
    "        \"n_estimators\": [n for n in range(50, 250, 50)],\n",
    "        \"ccp_alpha\": [0.01, 0.05, 0.10]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "    'Neural Net': GridSearchCV(estimator=MLPRegressor(solver=\"lbfgs\", max_iter=1000000), param_grid={\n",
    "        \"hidden_layer_sizes\": [(300, h1, h2)\n",
    "                               for h1 in range(100, 200, 50)\n",
    "                               for h2 in range(25, h1//2, 25)]\n",
    "    }, cv=split, scoring=\"explained_variance\", n_jobs=-1)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "for model_type, model in models.items():\n",
    "    model.fit(X_train, np.array(y_train).ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:--------------------------------------------------\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.4}\n",
      "  - Regression:\n",
      "    - MSE: 1.264388\n",
      "    - MAE: 0.484234\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[  0 498]\n",
      "       [   0 1329]]\n",
      "    - Accuracy: 0.727422\n",
      "    - Recall: 1.000000\n",
      "    - Precision: 0.727422\n",
      "    - F1-Score: 0.842205\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'degree': 2, 'kernel': 'rbf'}\n",
      "  - Regression:\n",
      "    - MSE: 1.498640\n",
      "    - MAE: 0.623448\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[187 311]\n",
      "       [602 727]]\n",
      "    - Accuracy: 0.500274\n",
      "    - Recall: 0.547028\n",
      "    - Precision: 0.700385\n",
      "    - F1-Score: 0.614280\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'ccp_alpha': 0.1, 'n_estimators': 100}\n",
      "  - Regression:\n",
      "    - MSE: 2.130246\n",
      "    - MAE: 0.500890\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[ 53 445]\n",
      "       [ 218 1111]]\n",
      "    - Accuracy: 0.637110\n",
      "    - Recall: 0.835967\n",
      "    - Precision: 0.714010\n",
      "    - F1-Score: 0.770191\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 150}\n",
      "  - Regression:\n",
      "    - MSE: 1.552794\n",
      "    - MAE: 0.613447\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[293 205]\n",
      "       [837 492]]\n",
      "    - Accuracy: 0.429666\n",
      "    - Recall: 0.370203\n",
      "    - Precision: 0.705882\n",
      "    - F1-Score: 0.485686\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'ccp_alpha': 0.1, 'n_estimators': 50}\n",
      "  - Regression:\n",
      "    - MSE: 1.247202\n",
      "    - MAE: 0.449698\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[  0 498]\n",
      "       [   0 1329]]\n",
      "    - Accuracy: 0.727422\n",
      "    - Recall: 1.000000\n",
      "    - Precision: 0.727422\n",
      "    - F1-Score: 0.842205\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (300, 150, 25)}\n",
      "  - Regression:\n",
      "    - MSE: 1.858354\n",
      "    - MAE: 0.750388\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[205 293]\n",
      "       [641 688]]\n",
      "    - Accuracy: 0.488779\n",
      "    - Recall: 0.517682\n",
      "    - Precision: 0.701325\n",
      "    - F1-Score: 0.595671\n",
      "--------------------------------------------------\n",
      "- Ensemble of all benchmark models\n",
      "  - Regression:\n",
      "    - MSE: 1.350504\n",
      "    - MAE: 0.516180\n",
      "--------------------------------------------------\n",
      "  - Classification\n",
      "    - Confusion Matrix:\n",
      "      [[ 39 459]\n",
      "       [ 143 1186]]\n",
      "    - Accuracy: 0.670498\n",
      "    - Recall: 0.892400\n",
      "    - Precision: 0.720973\n",
      "    - F1-Score: 0.797579\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results:\"\n",
    "      f\"--------------------------------------------------\")\n",
    "pred_average = None   # regression average\n",
    "pred_ensemble = None  # classification mean vote\n",
    "for model_type, model in models.items():\n",
    "    # regression results\n",
    "    print(f\"- Model: {model_type}\\n\"\n",
    "          f\"  - best parameters: {model.best_params_}\")\n",
    "    pred = model.predict(X_test)\n",
    "    if pred_average is None: pred_average = np.array(pred) / len(models)\n",
    "    else: pred_average = pred_average + (np.array(pred) / len(models))\n",
    "    print(f\"  - Regression:\\n\"\n",
    "          f\"    - MSE: {mean_squared_error(np.array(y_test), np.array(pred).ravel()):.06f}\\n\"\n",
    "          f\"    - MAE: {median_absolute_error(np.array(y_test), np.array(pred).ravel()):.06f}\")\n",
    "\n",
    "    # classification results\n",
    "    pred = [-1 if i < 0 else 1 for i in np.array(pred).ravel()]\n",
    "    if pred_ensemble is None: pred_ensemble = np.array(pred) / len(models)\n",
    "    else: pred_ensemble = pred_ensemble + (np.array(pred) / len(models))\n",
    "    conf_mat = confusion_matrix(\n",
    "        [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "        [0 if i < 0 else 1 for i in np.array(pred).ravel()])\n",
    "    accuracy = accuracy_score(\n",
    "        [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "        [0 if i < 0 else 1 for i in np.array(pred).ravel()])\n",
    "    precision = precision_score(\n",
    "        [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "        [0 if i < 0 else 1 for i in np.array(pred).ravel()])\n",
    "    recall = recall_score(\n",
    "        [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "        [0 if i < 0 else 1 for i in np.array(pred).ravel()])\n",
    "    f1 = f1_score(\n",
    "        [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "        [0 if i < 0 else 1 for i in np.array(pred).ravel()])\n",
    "    print(f\"  - Classification\\n\"\n",
    "          f\"    - Confusion Matrix:\\n\"\n",
    "          f\"      [{conf_mat[0]}\\n\"\n",
    "          f\"       {conf_mat[1]}]\\n\"\n",
    "          f\"    - Accuracy: {accuracy:.06f}\\n\"\n",
    "          f\"    - Recall: {recall:.06f}\\n\"\n",
    "          f\"    - Precision: {precision:.06f}\\n\"\n",
    "          f\"    - F1-Score: {f1:.06f}\\n\"\n",
    "          f\"--------------------------------------------------\")\n",
    "\n",
    "# ensemble of all benchmark models\n",
    "# regression results\n",
    "print(f\"- Ensemble of all benchmark models\")\n",
    "print(f\"  - Regression:\\n\"\n",
    "      f\"    - MSE: {mean_squared_error(np.array(y_test), np.array(pred_average).ravel()):.06f}\\n\"\n",
    "      f\"    - MAE: {median_absolute_error(np.array(y_test), np.array(pred_average).ravel()):.06f}\\n\"\n",
    "      f\"--------------------------------------------------\")\n",
    "\n",
    "# classification results\n",
    "conf_mat = confusion_matrix(\n",
    "    [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "    [0 if i < 0 else 1 for i in np.array(pred_ensemble).ravel()])\n",
    "accuracy = accuracy_score(\n",
    "    [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "    [0 if i < 0 else 1 for i in np.array(pred_ensemble).ravel()])\n",
    "precision = precision_score(\n",
    "    [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "    [0 if i < 0 else 1 for i in np.array(pred_ensemble).ravel()])\n",
    "recall = recall_score(\n",
    "    [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "    [0 if i < 0 else 1 for i in np.array(pred_ensemble).ravel()])\n",
    "f1 = f1_score(\n",
    "    [0 if i < 0 else 1 for i in y_test.to_numpy().ravel()],\n",
    "    [0 if i < 0 else 1 for i in np.array(pred_ensemble).ravel()])\n",
    "print(f\"  - Classification\\n\"\n",
    "      f\"    - Confusion Matrix:\\n\"\n",
    "      f\"      [{conf_mat[0]}\\n\"\n",
    "      f\"       {conf_mat[1]}]\\n\"\n",
    "      f\"    - Accuracy: {accuracy:.06f}\\n\"\n",
    "      f\"    - Recall: {recall:.06f}\\n\"\n",
    "      f\"    - Precision: {precision:.06f}\\n\"\n",
    "      f\"    - F1-Score: {f1:.06f}\\n\"\n",
    "      f\"--------------------------------------------------\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}